{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>phon_R01_S50_2</td>\n",
       "      <td>174.188</td>\n",
       "      <td>230.978</td>\n",
       "      <td>94.261</td>\n",
       "      <td>0.00459</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00263</td>\n",
       "      <td>0.00259</td>\n",
       "      <td>0.00790</td>\n",
       "      <td>0.04087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07008</td>\n",
       "      <td>0.02764</td>\n",
       "      <td>19.517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448439</td>\n",
       "      <td>0.657899</td>\n",
       "      <td>-6.538586</td>\n",
       "      <td>0.121952</td>\n",
       "      <td>2.657476</td>\n",
       "      <td>0.133050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>phon_R01_S50_3</td>\n",
       "      <td>209.516</td>\n",
       "      <td>253.017</td>\n",
       "      <td>89.488</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.00292</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.02751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04812</td>\n",
       "      <td>0.01810</td>\n",
       "      <td>19.147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431674</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>-6.195325</td>\n",
       "      <td>0.129303</td>\n",
       "      <td>2.784312</td>\n",
       "      <td>0.168895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>phon_R01_S50_4</td>\n",
       "      <td>174.688</td>\n",
       "      <td>240.005</td>\n",
       "      <td>74.287</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00624</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.01873</td>\n",
       "      <td>0.02308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03804</td>\n",
       "      <td>0.10715</td>\n",
       "      <td>17.883</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407567</td>\n",
       "      <td>0.655683</td>\n",
       "      <td>-6.787197</td>\n",
       "      <td>0.158453</td>\n",
       "      <td>2.679772</td>\n",
       "      <td>0.131728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>phon_R01_S50_5</td>\n",
       "      <td>198.764</td>\n",
       "      <td>396.961</td>\n",
       "      <td>74.904</td>\n",
       "      <td>0.00740</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.02296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03794</td>\n",
       "      <td>0.07223</td>\n",
       "      <td>19.020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451221</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>-6.744577</td>\n",
       "      <td>0.207454</td>\n",
       "      <td>2.138608</td>\n",
       "      <td>0.123306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>phon_R01_S50_6</td>\n",
       "      <td>214.289</td>\n",
       "      <td>260.277</td>\n",
       "      <td>77.973</td>\n",
       "      <td>0.00567</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>0.00885</td>\n",
       "      <td>0.01884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03078</td>\n",
       "      <td>0.04398</td>\n",
       "      <td>21.209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462803</td>\n",
       "      <td>0.664357</td>\n",
       "      <td>-5.724056</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>2.555477</td>\n",
       "      <td>0.148569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0    phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1    phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2    phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3    phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4    phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "..              ...          ...           ...           ...             ...   \n",
       "190  phon_R01_S50_2      174.188       230.978        94.261         0.00459   \n",
       "191  phon_R01_S50_3      209.516       253.017        89.488         0.00564   \n",
       "192  phon_R01_S50_4      174.688       240.005        74.287         0.01360   \n",
       "193  phon_R01_S50_5      198.764       396.961        74.904         0.00740   \n",
       "194  phon_R01_S50_6      214.289       260.277        77.973         0.00567   \n",
       "\n",
       "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0             0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1             0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2             0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3             0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4             0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "..                ...       ...       ...         ...           ...  ...   \n",
       "190           0.00003   0.00263   0.00259     0.00790       0.04087  ...   \n",
       "191           0.00003   0.00331   0.00292     0.00994       0.02751  ...   \n",
       "192           0.00008   0.00624   0.00564     0.01873       0.02308  ...   \n",
       "193           0.00004   0.00370   0.00390     0.01109       0.02296  ...   \n",
       "194           0.00003   0.00295   0.00317     0.00885       0.01884  ...   \n",
       "\n",
       "     Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0        0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1        0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2        0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3        0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4        0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "..           ...      ...     ...     ...       ...       ...       ...   \n",
       "190      0.07008  0.02764  19.517       0  0.448439  0.657899 -6.538586   \n",
       "191      0.04812  0.01810  19.147       0  0.431674  0.683244 -6.195325   \n",
       "192      0.03804  0.10715  17.883       0  0.407567  0.655683 -6.787197   \n",
       "193      0.03794  0.07223  19.020       0  0.451221  0.643956 -6.744577   \n",
       "194      0.03078  0.04398  21.209       0  0.462803  0.664357 -5.724056   \n",
       "\n",
       "      spread2        D2       PPE  \n",
       "0    0.266482  2.301442  0.284654  \n",
       "1    0.335590  2.486855  0.368674  \n",
       "2    0.311173  2.342259  0.332634  \n",
       "3    0.334147  2.405554  0.368975  \n",
       "4    0.234513  2.332180  0.410335  \n",
       "..        ...       ...       ...  \n",
       "190  0.121952  2.657476  0.133050  \n",
       "191  0.129303  2.784312  0.168895  \n",
       "192  0.158453  2.679772  0.131728  \n",
       "193  0.207454  2.138608  0.123306  \n",
       "194  0.190667  2.555477  0.148569  \n",
       "\n",
       "[195 rows x 24 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkinson = pd.read_csv('parkinsonDataset.csv')\n",
    "parkinson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkinson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parkinson.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                0\n",
       "MDVP:Fo(Hz)         0\n",
       "MDVP:Fhi(Hz)        0\n",
       "MDVP:Flo(Hz)        0\n",
       "MDVP:Jitter(%)      0\n",
       "MDVP:Jitter(Abs)    0\n",
       "MDVP:RAP            0\n",
       "MDVP:PPQ            0\n",
       "Jitter:DDP          0\n",
       "MDVP:Shimmer        0\n",
       "MDVP:Shimmer(dB)    0\n",
       "Shimmer:APQ3        0\n",
       "Shimmer:APQ5        0\n",
       "MDVP:APQ            0\n",
       "Shimmer:DDA         0\n",
       "NHR                 0\n",
       "HNR                 0\n",
       "status              0\n",
       "RPDE                0\n",
       "DFA                 0\n",
       "spread1             0\n",
       "spread2             0\n",
       "D2                  0\n",
       "PPE                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkinson.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: Index(['name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for categorical columns\n",
    "categorical_cols = parkinson.select_dtypes(include=['object']).columns\n",
    "print(f\"Categorical columns: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = parkinson.drop(columns=['name','status'])  # Drop 'name' and 'status' columns\n",
    "y = parkinson['status']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
      "0        119.992       157.302        74.997         0.00784   \n",
      "1        122.400       148.650       113.819         0.00968   \n",
      "2        116.682       131.111       111.555         0.01050   \n",
      "3        116.676       137.871       111.366         0.00997   \n",
      "4        116.014       141.781       110.655         0.01284   \n",
      "..           ...           ...           ...             ...   \n",
      "190      174.188       230.978        94.261         0.00459   \n",
      "191      209.516       253.017        89.488         0.00564   \n",
      "192      174.688       240.005        74.287         0.01360   \n",
      "193      198.764       396.961        74.904         0.00740   \n",
      "194      214.289       260.277        77.973         0.00567   \n",
      "\n",
      "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
      "0             0.00007   0.00370   0.00554     0.01109       0.04374   \n",
      "1             0.00008   0.00465   0.00696     0.01394       0.06134   \n",
      "2             0.00009   0.00544   0.00781     0.01633       0.05233   \n",
      "3             0.00009   0.00502   0.00698     0.01505       0.05492   \n",
      "4             0.00011   0.00655   0.00908     0.01966       0.06425   \n",
      "..                ...       ...       ...         ...           ...   \n",
      "190           0.00003   0.00263   0.00259     0.00790       0.04087   \n",
      "191           0.00003   0.00331   0.00292     0.00994       0.02751   \n",
      "192           0.00008   0.00624   0.00564     0.01873       0.02308   \n",
      "193           0.00004   0.00370   0.00390     0.01109       0.02296   \n",
      "194           0.00003   0.00295   0.00317     0.00885       0.01884   \n",
      "\n",
      "     MDVP:Shimmer(dB)  ...  MDVP:APQ  Shimmer:DDA      NHR     HNR      RPDE  \\\n",
      "0               0.426  ...   0.02971      0.06545  0.02211  21.033  0.414783   \n",
      "1               0.626  ...   0.04368      0.09403  0.01929  19.085  0.458359   \n",
      "2               0.482  ...   0.03590      0.08270  0.01309  20.651  0.429895   \n",
      "3               0.517  ...   0.03772      0.08771  0.01353  20.644  0.434969   \n",
      "4               0.584  ...   0.04465      0.10470  0.01767  19.649  0.417356   \n",
      "..                ...  ...       ...          ...      ...     ...       ...   \n",
      "190             0.405  ...   0.02745      0.07008  0.02764  19.517  0.448439   \n",
      "191             0.263  ...   0.01879      0.04812  0.01810  19.147  0.431674   \n",
      "192             0.256  ...   0.01667      0.03804  0.10715  17.883  0.407567   \n",
      "193             0.241  ...   0.01588      0.03794  0.07223  19.020  0.451221   \n",
      "194             0.190  ...   0.01373      0.03078  0.04398  21.209  0.462803   \n",
      "\n",
      "          DFA   spread1   spread2        D2       PPE  \n",
      "0    0.815285 -4.813031  0.266482  2.301442  0.284654  \n",
      "1    0.819521 -4.075192  0.335590  2.486855  0.368674  \n",
      "2    0.825288 -4.443179  0.311173  2.342259  0.332634  \n",
      "3    0.819235 -4.117501  0.334147  2.405554  0.368975  \n",
      "4    0.823484 -3.747787  0.234513  2.332180  0.410335  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "190  0.657899 -6.538586  0.121952  2.657476  0.133050  \n",
      "191  0.683244 -6.195325  0.129303  2.784312  0.168895  \n",
      "192  0.655683 -6.787197  0.158453  2.679772  0.131728  \n",
      "193  0.643956 -6.744577  0.207454  2.138608  0.123306  \n",
      "194  0.664357 -5.724056  0.190667  2.555477  0.148569  \n",
      "\n",
      "[195 rows x 22 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "190    0\n",
      "191    0\n",
      "192    0\n",
      "193    0\n",
      "194    0\n",
      "Name: status, Length: 195, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 22)\n",
      "(195,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Fit the scaler on the entire dataset, then split and transform\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# Fit on the entire feature set X and target y before splitting\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18430827, 0.11259173, 0.05481479, ..., 0.58576513, 0.39066128,\n",
       "        0.4973096 ],\n",
       "       [0.19832685, 0.09493044, 0.2783228 , ..., 0.74133704, 0.47314522,\n",
       "        0.67132602],\n",
       "       [0.16503854, 0.05912816, 0.26528838, ..., 0.68637091, 0.40881938,\n",
       "        0.59668246],\n",
       "       ...,\n",
       "       [0.50273036, 0.28141298, 0.05072714, ..., 0.34257652, 0.55896743,\n",
       "        0.18057983],\n",
       "       [0.6428929 , 0.60180655, 0.05427936, ..., 0.45288473, 0.31822198,\n",
       "        0.16313677],\n",
       "       [0.73327434, 0.32279413, 0.07194837, ..., 0.41509481, 0.50367281,\n",
       "        0.21545975]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53480777 0.20230054 0.63318249 0.03684879 0.0513834  0.04094412\n",
      " 0.03965702 0.04093755 0.04473252 0.03779786 0.05219569 0.04274084\n",
      " 0.03606708 0.05218898 0.00528376 0.74359912 0.34372499 0.76463112\n",
      " 0.27353803 0.46378025 0.376406   0.20170744]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64559416 0.21916776 0.72895437 0.02318933 0.01185771 0.03179191\n",
      " 0.02465166 0.0317868  0.00556874 0.00328677 0.0094376  0.00963365\n",
      " 0.00329275 0.00956477 0.00324665 0.91437048 0.41035184 0.66840235\n",
      " 0.05105757 0.376042   0.30242835 0.04962844]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training (70%), testing (15%), and validation (15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 22)\n",
      "(136, 22)\n",
      "(29, 22)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_val))\n",
    "#print(np.shape(y_val))\n",
    "print(np.shape(X_train))\n",
    "#print(np.shape(y_train))\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train and X_test: (136, 22) (29, 22)\n",
      "Shape of y_train and y_test: (136, 1) (29, 1)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of training and testing sets\n",
    "print(\"Shape of X_train and X_test:\", X_train.shape, X_test.shape)\n",
    "print(\"Shape of y_train and y_test:\", y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Input layer and hidden layers\n",
    "model.add(tf.keras.layers.Input(shape=(22,)))  # 22 input features\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer for binary classification\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Single output node with sigmoid\n",
    "\n",
    "# Compile the model for binary classification\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 64)                1472      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,585\n",
      "Trainable params: 3,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_OF_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1879 - accuracy: 0.9191 - val_loss: 0.1807 - val_accuracy: 0.9333\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1863 - accuracy: 0.9118 - val_loss: 0.1777 - val_accuracy: 0.9333\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1838 - accuracy: 0.9118 - val_loss: 0.1779 - val_accuracy: 0.9333\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1808 - accuracy: 0.9191 - val_loss: 0.1774 - val_accuracy: 0.9333\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1783 - accuracy: 0.9191 - val_loss: 0.1816 - val_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1786 - accuracy: 0.9265 - val_loss: 0.1709 - val_accuracy: 0.9333\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1744 - accuracy: 0.9265 - val_loss: 0.1678 - val_accuracy: 0.9333\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1727 - accuracy: 0.9118 - val_loss: 0.1669 - val_accuracy: 0.9333\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1711 - accuracy: 0.9265 - val_loss: 0.1788 - val_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1721 - accuracy: 0.9412 - val_loss: 0.1774 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1683 - accuracy: 0.9338 - val_loss: 0.1655 - val_accuracy: 0.9333\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1670 - accuracy: 0.9191 - val_loss: 0.1647 - val_accuracy: 0.9333\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1650 - accuracy: 0.9191 - val_loss: 0.1613 - val_accuracy: 0.9333\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1599 - accuracy: 0.9265 - val_loss: 0.1619 - val_accuracy: 0.9333\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1581 - accuracy: 0.9265 - val_loss: 0.1591 - val_accuracy: 0.9333\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1581 - accuracy: 0.9191 - val_loss: 0.1557 - val_accuracy: 0.9333\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1603 - accuracy: 0.9118 - val_loss: 0.1550 - val_accuracy: 0.9333\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1509 - accuracy: 0.9485 - val_loss: 0.1772 - val_accuracy: 0.9333\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1597 - accuracy: 0.9632 - val_loss: 0.1761 - val_accuracy: 0.9333\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1543 - accuracy: 0.9485 - val_loss: 0.1520 - val_accuracy: 0.9333\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1479 - accuracy: 0.9338 - val_loss: 0.1506 - val_accuracy: 0.9333\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1487 - accuracy: 0.9338 - val_loss: 0.1487 - val_accuracy: 0.9333\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1450 - accuracy: 0.9559 - val_loss: 0.1573 - val_accuracy: 0.9333\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1454 - accuracy: 0.9559 - val_loss: 0.1510 - val_accuracy: 0.9667\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1406 - accuracy: 0.9559 - val_loss: 0.1431 - val_accuracy: 0.9333\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1453 - accuracy: 0.9265 - val_loss: 0.1412 - val_accuracy: 0.9333\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1409 - accuracy: 0.9338 - val_loss: 0.1397 - val_accuracy: 0.9333\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1412 - accuracy: 0.9632 - val_loss: 0.1470 - val_accuracy: 0.9667\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1362 - accuracy: 0.9632 - val_loss: 0.1390 - val_accuracy: 0.9667\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1327 - accuracy: 0.9632 - val_loss: 0.1377 - val_accuracy: 0.9667\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1319 - accuracy: 0.9559 - val_loss: 0.1365 - val_accuracy: 0.9667\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1315 - accuracy: 0.9559 - val_loss: 0.1320 - val_accuracy: 0.9667\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1289 - accuracy: 0.9559 - val_loss: 0.1316 - val_accuracy: 0.9667\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1259 - accuracy: 0.9632 - val_loss: 0.1354 - val_accuracy: 0.9333\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1266 - accuracy: 0.9706 - val_loss: 0.1280 - val_accuracy: 0.9333\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1244 - accuracy: 0.9632 - val_loss: 0.1261 - val_accuracy: 0.9333\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1268 - accuracy: 0.9485 - val_loss: 0.1250 - val_accuracy: 0.9333\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1229 - accuracy: 0.9632 - val_loss: 0.1258 - val_accuracy: 0.9667\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1235 - accuracy: 0.9706 - val_loss: 0.1305 - val_accuracy: 0.9333\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1206 - accuracy: 0.9706 - val_loss: 0.1239 - val_accuracy: 0.9333\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1190 - accuracy: 0.9632 - val_loss: 0.1232 - val_accuracy: 0.9667\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1160 - accuracy: 0.9706 - val_loss: 0.1283 - val_accuracy: 0.9667\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1185 - accuracy: 0.9706 - val_loss: 0.1360 - val_accuracy: 0.9333\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1171 - accuracy: 0.9632 - val_loss: 0.1220 - val_accuracy: 0.9667\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1139 - accuracy: 0.9706 - val_loss: 0.1182 - val_accuracy: 0.9667\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1132 - accuracy: 0.9706 - val_loss: 0.1160 - val_accuracy: 0.9667\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1106 - accuracy: 0.9706 - val_loss: 0.1146 - val_accuracy: 0.9667\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1110 - accuracy: 0.9779 - val_loss: 0.1158 - val_accuracy: 0.9667\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1126 - accuracy: 0.9706 - val_loss: 0.1130 - val_accuracy: 0.9667\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1089 - accuracy: 0.9706 - val_loss: 0.1130 - val_accuracy: 0.9667\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1058 - accuracy: 0.9706 - val_loss: 0.1157 - val_accuracy: 0.9667\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1056 - accuracy: 0.9779 - val_loss: 0.1203 - val_accuracy: 0.9333\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1052 - accuracy: 0.9779 - val_loss: 0.1150 - val_accuracy: 0.9667\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1021 - accuracy: 0.9779 - val_loss: 0.1106 - val_accuracy: 0.9667\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1032 - accuracy: 0.9706 - val_loss: 0.1109 - val_accuracy: 0.9667\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1022 - accuracy: 0.9779 - val_loss: 0.1203 - val_accuracy: 0.9333\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1007 - accuracy: 0.9779 - val_loss: 0.1145 - val_accuracy: 0.9667\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1021 - accuracy: 0.9779 - val_loss: 0.1099 - val_accuracy: 0.9667\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1000 - accuracy: 0.9706 - val_loss: 0.1215 - val_accuracy: 0.9333\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0998 - accuracy: 0.9779 - val_loss: 0.1106 - val_accuracy: 0.9667\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0962 - accuracy: 0.9779 - val_loss: 0.1093 - val_accuracy: 0.9667\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0947 - accuracy: 0.9779 - val_loss: 0.1058 - val_accuracy: 0.9667\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0942 - accuracy: 0.9779 - val_loss: 0.1072 - val_accuracy: 0.9667\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0926 - accuracy: 0.9779 - val_loss: 0.1116 - val_accuracy: 0.9333\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0920 - accuracy: 0.9779 - val_loss: 0.1099 - val_accuracy: 0.9333\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0922 - accuracy: 0.9779 - val_loss: 0.1098 - val_accuracy: 0.9333\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9779 - val_loss: 0.1033 - val_accuracy: 0.9667\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0902 - accuracy: 0.9779 - val_loss: 0.1016 - val_accuracy: 0.9667\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0910 - accuracy: 0.9779 - val_loss: 0.1036 - val_accuracy: 0.9667\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0885 - accuracy: 0.9779 - val_loss: 0.1164 - val_accuracy: 0.9000\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0892 - accuracy: 0.9779 - val_loss: 0.1119 - val_accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0859 - accuracy: 0.9779 - val_loss: 0.1016 - val_accuracy: 0.9667\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0880 - accuracy: 0.9853 - val_loss: 0.1006 - val_accuracy: 0.9667\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.9779 - val_loss: 0.1086 - val_accuracy: 0.9333\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0856 - accuracy: 0.9779 - val_loss: 0.1082 - val_accuracy: 0.9333\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0851 - accuracy: 0.9853 - val_loss: 0.1074 - val_accuracy: 0.9333\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0866 - accuracy: 0.9779 - val_loss: 0.0974 - val_accuracy: 0.9667\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0798 - accuracy: 0.9779 - val_loss: 0.1031 - val_accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0790 - accuracy: 0.9779 - val_loss: 0.1113 - val_accuracy: 0.9000\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0792 - accuracy: 0.9779 - val_loss: 0.1098 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0777 - accuracy: 0.9779 - val_loss: 0.1007 - val_accuracy: 0.9667\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0769 - accuracy: 0.9779 - val_loss: 0.0974 - val_accuracy: 0.9667\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0757 - accuracy: 0.9779 - val_loss: 0.0947 - val_accuracy: 0.9667\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0776 - accuracy: 0.9853 - val_loss: 0.0948 - val_accuracy: 0.9667\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0741 - accuracy: 0.9779 - val_loss: 0.1089 - val_accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0750 - accuracy: 0.9779 - val_loss: 0.1178 - val_accuracy: 0.9333\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0765 - accuracy: 0.9779 - val_loss: 0.1045 - val_accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0702 - accuracy: 0.9779 - val_loss: 0.0926 - val_accuracy: 0.9667\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0764 - accuracy: 0.9853 - val_loss: 0.0930 - val_accuracy: 0.9667\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0725 - accuracy: 0.9853 - val_loss: 0.0921 - val_accuracy: 0.9667\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0700 - accuracy: 0.9853 - val_loss: 0.1024 - val_accuracy: 0.9667\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0746 - accuracy: 0.9853 - val_loss: 0.0950 - val_accuracy: 0.9333\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0745 - accuracy: 0.9779 - val_loss: 0.0908 - val_accuracy: 0.9667\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0707 - accuracy: 0.9853 - val_loss: 0.0934 - val_accuracy: 0.9667\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0669 - accuracy: 0.9779 - val_loss: 0.1025 - val_accuracy: 0.9000\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.9779 - val_loss: 0.1008 - val_accuracy: 0.9000\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0707 - accuracy: 0.9853 - val_loss: 0.0945 - val_accuracy: 0.9667\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0693 - accuracy: 0.9853 - val_loss: 0.0994 - val_accuracy: 0.9000\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0659 - accuracy: 0.9853 - val_loss: 0.1001 - val_accuracy: 0.9000\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0646 - accuracy: 0.9779 - val_loss: 0.0940 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_OF_EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val,y_val)  # Use 20% of the training data for validation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2685 - accuracy: 0.8966\n",
      "Test Score (Loss): 0.26852601766586304\n",
      "Test Accuracy: 0.8965517282485962\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Print test loss and accuracy\n",
    "print(\"Test Score (Loss):\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'parkinson.h5'\n"
     ]
    }
   ],
   "source": [
    "# Save the model in HDF5 format\n",
    "model.save('parkinson.h5')\n",
    "print(\"Model saved as 'parkinson.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.13044035, 0.02337692, 0.19956361, 0.05972046, 0.09090909,\n",
      "        0.04913295, 0.05787781, 0.04912506, 0.04838415, 0.03944125,\n",
      "        0.0575886 , 0.05156038, 0.04334176, 0.0575812 , 0.01161791,\n",
      "        0.7359587 , 0.26254082, 0.80426764, 0.33979985, 0.41893977,\n",
      "        0.20718075, 0.2684455 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a representative dataset generator for TensorFlow Lite quantization\n",
    "def representative_dataset():\n",
    "    for i in range(100):\n",
    "        # Use indexing to get the row at the specified index\n",
    "        data = X_test[i % len(X_test)]  # Cycle through X_test if i > len(X_test)\n",
    "        yield [np.array([data], dtype=np.float32)]  # Convert to float32 and add batch dimension\n",
    "\n",
    "# Test the function output\n",
    "for sample in representative_dataset():\n",
    "    print(sample)\n",
    "    break  # Print one sample to verify and then exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_lenses_model_dir\\assets\n",
      "Model converted and saved as 'parkinson.tflite'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Save the model in the SavedModel format\n",
    "tf.saved_model.save(model, \"saved_lenses_model_dir\")\n",
    "\n",
    "# Load the saved model with TFLiteConverter\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_lenses_model_dir\")\n",
    "\n",
    "# Set optimization to reduce the model size if desired (optional)\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Define a representative dataset generator for TFLite (required for quantization)\n",
    "def representative_dataset():\n",
    "    for i in range(100):\n",
    "        # Randomly sample data for optimization (you may replace this with actual data samples if needed)\n",
    "        yield [np.array(X.sample(1), dtype=np.float32)]\n",
    "\n",
    "# Set the representative dataset for quantization\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model to a .tflite file\n",
    "with open(\"parkinsonl.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model converted and saved as 'parkinson.tflite'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'parkinson.tflite'\n"
     ]
    }
   ],
   "source": [
    "# Save the model in TFLite format\n",
    "with open(\"parkinson.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model saved as 'parkinson.tflite'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model loaded and tensors allocated.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"parkinson.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "print(\"TFLite model loaded and tensors allocated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details:\n",
      " [{'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([ 1, 22]), 'shape_signature': array([-1, 22]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details:\n",
      " [{'name': 'StatefulPartitionedCall:0', 'index': 10, 'shape': array([1, 1]), 'shape_signature': array([-1,  1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# Get input and output tensor details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Display input and output details\n",
    "print(\"Input details:\\n\", input_details)\n",
    "print(\"Output details:\\n\", output_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " [[0.18430827 0.11259173 0.05481479 0.1956798  0.24901186 0.14547206\n",
      "  0.24758842 0.14528817 0.31221472 0.28019721 0.33262712 0.34735414\n",
      "  0.17244812 0.33258441 0.06830697 0.5117451  0.36915542 0.96014836\n",
      "  0.56987521 0.58576513 0.39066128 0.4973096 ]\n",
      " [0.19832685 0.09493044 0.2783228  0.25412961 0.28853755 0.19123314\n",
      "  0.32368703 0.1910419  0.47288662 0.44453574 0.51598613 0.53568521\n",
      "  0.27942415 0.51604827 0.05933094 0.43257742 0.47083048 0.97702445\n",
      "  0.70327699 0.74133704 0.47314522 0.67132602]]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\\n\", X_scaled[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details:\n",
      " [{'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([ 1, 22]), 'shape_signature': array([-1, 22]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details:\n",
      " [{'name': 'StatefulPartitionedCall:0', 'index': 10, 'shape': array([1, 1]), 'shape_signature': array([-1,  1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Random input output: [[0.99796194]]\n",
      "Sample from X_test output: [[0.13228561]]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Original model output for X_test sample: [[0.13228564]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"parkinson.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Display input and output details for verification\n",
    "print(\"Input details:\\n\", input_details)\n",
    "print(\"Output details:\\n\", output_details)\n",
    "\n",
    "# 1. Test with random input data to check functionality\n",
    "input_shape = input_details[0]['shape']\n",
    "random_input_data = np.random.random_sample(input_shape).astype(np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], random_input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Random input output:\", output_data)\n",
    "\n",
    "# 2. Test with a sample from X_test\n",
    "# Assuming X_test is a DataFrame, we take a sample and convert it to a numpy array\n",
    "sample_input_data = np.array([X_test[0]], dtype=np.float32)  # Accessing the first row of X_test\n",
    "interpreter.set_tensor(input_details[0]['index'], sample_input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "sample_output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Sample from X_test output:\", sample_output_data)\n",
    "\n",
    "# Verify with the original model\n",
    "original_model_output = model.predict(sample_input_data)\n",
    "print(\"Original model output for X_test sample:\", original_model_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "DENSE1_SIZE = 64\n",
    "DENSE2_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to convert hex values into a C array for deployment on ESP32\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "    c_str = \"\"\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += \"#define \" + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    c_str += \"/*\\n Author: Kashish Varma Auto Generated\\n\"\n",
    "    c_str += \" CAUTION: This is an auto-generated file.\\n DO NOT EDIT OR MAKE ANY CHANGES TO IT.\\n\"\n",
    "\n",
    "    # Time stamp for this model data in the generated file\n",
    "    localtime = time.asctime(time.localtime(time.time()))\n",
    "    c_str += \" This model data was generated on \" + localtime + '\\n\\n'\n",
    "    print(\"This model data was generated on:\", localtime)\n",
    "\n",
    "    # Add information about tool versions used in generating this header file\n",
    "    c_str += \" Tools used:\\n Python:\" + str(sys.version) + \"\\n Numpy:\" + str(np.__version__) + \\\n",
    "          \"\\n TensorFlow:\" + str(tf.__version__) + \"\\n Keras: \" + str(tf.keras.__version__) + \"\\n\\n\"\n",
    "    print(\"Tools used: Python:\", sys.version, \"\\n Numpy:\", np.__version__, \\\n",
    "          \"\\n TensorFlow:\", tf.__version__, \"\\n Keras:\", tf.keras.__version__, \"\\n\\n\")\n",
    "\n",
    "    # Training details of the model\n",
    "    c_str += ' Model details are:\\n'\n",
    "    c_str += ' NUM_OF_EPOCHS = ' + str(NUM_OF_EPOCHS) + '\\n'\n",
    "    c_str += ' BATCH_SIZE    = ' + str(BATCH_SIZE) + '\\n*/\\n'\n",
    "\n",
    "    # Generate 'C' constants for the number of nodes in each layer\n",
    "    c_str += '\\nconst int ' + 'DENSE1_SIZE' + ' = ' + str(DENSE1_SIZE) + ';\\n'\n",
    "    c_str +=   'const int ' + 'DENSE2_SIZE' + ' = ' + str(DENSE2_SIZE) + ';\\n'      \n",
    "\n",
    "    # Add array length at the top of the file\n",
    "    c_str += '\\nconst unsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'alignas(8) const unsigned char ' + var_name + '[] = {\\n'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data):\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add comma for formatting and newlines to stay within 80 characters per line\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n'\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n' + ''.join(hex_array) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `tflite_model_content` contains the raw byte data of the TFLite model\n",
    "# with open(\"LensesClassifyModel.tflite\", \"rb\") as f:\n",
    "#     tflite_model_content = f.read()\n",
    "\n",
    "# Convert to C array format\n",
    "# c_code = hex_to_c_array(tflite_model_content, \"LensesClassifyModel\")\n",
    "# print(c_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model data was generated on: Sun Nov 10 23:10:24 2024\n",
      "Tools used: Python: 3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)] \n",
      " Numpy: 1.21.5 \n",
      " TensorFlow: 2.10.0 \n",
      " Keras: 2.10.0 \n",
      "\n",
      "\n",
      "Model saved as 'parkinson_esp32.h'\n"
     ]
    }
   ],
   "source": [
    "# Save the TFLite model as a C source (.h) file for ESP32 deployment\n",
    "with open(\"parkinson_esp32.h\", 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model, \"parkinson_esp32\"))\n",
    "\n",
    "print(\"Model saved as 'parkinson_esp32.h'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Expected output for Input1: [[0.81567055]]\n",
      "Expected output for Input2: [[0.5001658]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define inputs matching the ESP32 inputs\n",
    "input1 = np.array([[0.53480777, 0.20230054, 0.63318249, 0.03684879, 0.0513834,  0.04094412, 0.03965702, 0.04093755, 0.04473252, 0.03779786, 0.05219569, 0.04274084, 0.03606708, 0.05218898, 0.00528376, 0.74359912, 0.34372499, 0.76463112, 0.27353803, 0.46378025, 0.376406,   0.20170744]], dtype=np.float32) \n",
    "\n",
    "\n",
    "input2 = np.array([[0.13044035, 0.02337691, 0.1995636,  0.05972046, 0.09090909, 0.04913295, 0.05787781, 0.04912506, 0.04838415, 0.03944125, 0.0575886,  0.05156038, 0.04334176, 0.0575812,  0.01161791, 0.73595871, 0.2625408,  0.80426763, 0.33979985, 0.41893976, 0.20718076, 0.26844549]], dtype=np.float32) \n",
    "\n",
    "# Assuming the trained Keras model is loaded as `model`\n",
    "output1 = model.predict(input1)\n",
    "output2 = model.predict(input2)\n",
    "\n",
    "# Display the expected output probabilities\n",
    "print(\"Expected output for Input1:\", output1)\n",
    "print(\"Expected output for Input2:\", output2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sem5_py_37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
